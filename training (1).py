# -*- coding: utf-8 -*-
"""training.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tEiLU9Ua6XPuu_aRX4rhgQrBjxJQBlWl
"""

os.environ["OPENAI_API_KEY"] = input("Paste your OpenAI key here and hit enter:") # This makes the API key available to the OpenAI class from the langchain library, which is used to initialize the GPT-3 language model.
#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

# Create a SimpleDirectoryReader object and load data from the 'data' directory
documents = SimpleDirectoryReader('data').load_data()


#step2 


# set the directory path
data_dir = '/path/to/data/folder'

# get a list of all .txt files in the directory
file_list = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.txt')]

# read the text content of each file and create a Document object for each
text_list = []
for file_path in file_list:
    with open(file_path, 'r') as f:
        text = f.read()
        text_list.append(text)



#step3

documents = [Document(t) for t in text_list]

# Create a SimpleNodeParser object
parser = SimpleNodeParser()

# Get nodes from the specified documents using the SimpleNodeParser object
nodes = parser.get_nodes_from_documents(documents)

# Create two new nodes with  text and IDs
node1 = Node(text="<text_chunk>", doc_id="<node_id>")
node2 = Node(text="<text_chunk>", doc_id="<node_id>")

# Set relationships between the two nodes
node1.relationships[DocumentRelationship.NEXT] = node2.get_doc_id()
node2.relationships[DocumentRelationship.PREVIOUS] = node1.get_doc_id()

# Create a new GPTSimpleVectorIndex object from the specified documents
index = GPTSimpleVectorIndex.from_documents(documents)

# Create a new GPTSimpleVectorIndex object from the specified nodes
index = GPTSimpleVectorIndex(nodes)

# Create a new empty GPTSimpleVectorIndex object
index = GPTSimpleVectorIndex([])

# Insert each document in the 'documents' list into the empty index
for doc in documents:
    index.insert(doc)



construct_index("context_data/data") #creates an index of documents located in the "context_data/data" directory using a GPT-based vector index.



ask_ai() #The function then enters a loop where it prompts the user to enter a query using the input() function